# -*- coding: utf-8 -*-
"""CNN_MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UfHQmkSt3kESaLYSYQHTxIV3Fw1kfGRA
"""

import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt

# --- 1. Load and Prepare the Data ---
print("Loading and preparing the MNIST dataset...")

# Load the MNIST dataset (handwritten digits 0-9)
# (x_train is the training images, y_train is the training labels)
# (x_test is the test images, y_test is the test labels)
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Check the shape of the data
print(f"Original training data shape: {x_train.shape}")
print(f"Original test data shape: {x_test.shape}")

# Preprocessing steps:

# a) Reshape the data for the CNN (add a channel dimension)
# MNIST images are 28x28 grayscale. CNNs expect a format like (samples, rows, cols, channels)
# For grayscale, the channel is 1.
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)

# b) Normalize the pixel values
# Convert integer data type to float32 and scale from 0-255 to 0-1
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# c) Convert class vectors to binary class matrices (One-Hot Encoding)
# e.g., the label 5 is converted to [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
num_classes = 10 # Digits 0 through 9
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

print("Data preparation complete.")
print(f"Normalized and reshaped training data shape: {x_train.shape}")

# --- 2. Define the CNN Model Architecture ---
print("\nDefining the Convolutional Neural Network (CNN) model...")

model = Sequential([
    # Convolutional Layer: Learns features (edges, curves, etc.)
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),

    # Pooling Layer: Reduces dimensionality, makes the model more robust to shifts
    MaxPooling2D((2, 2)),

    # Another set of Conv and Pool layers for deeper feature extraction
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    # Flatten Layer: Converts the 2D feature maps into a 1D vector for the Dense layers
    Flatten(),

    # Dense Layer (Hidden Layer): Standard neural network layer
    Dense(100, activation='relu'),

    # Output Layer: 10 neurons (one for each digit 0-9) with softmax for probability distribution
    Dense(num_classes, activation='softmax')
])

# Display the model's structure
model.summary()

# --- 3. Compile the Model ---
# 'adam' is a good all-purpose optimizer.
# 'categorical_crossentropy' is used for multi-class classification with one-hot encoded labels.
# 'accuracy' is the metric we want to track.
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# --- 4. Train the Model ---
print("\nStarting model training...")

# Train the model on the training data
history = model.fit(
    x_train, y_train,
    epochs=10,            # Number of times to iterate over the entire training dataset
    batch_size=128,       # Number of samples per gradient update
    validation_data=(x_test, y_test) # Use test data to monitor performance during training
)

print("Model training complete.")

# --- 5. Evaluate the Model ---
print("\nEvaluating the model on the test dataset...")

# Evaluate the model on the test data to get final accuracy and loss
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)

print(f"\nTest Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_acc*100:.2f}%")

# --- 6. Make a Prediction and Visualize ---
print("\nMaking a prediction on a sample image...")

# Get the first image from the test set for a prediction
sample_image = x_test[0]
true_label = np.argmax(y_test[0]) # Convert one-hot back to a single number

# The model expects a batch of images, so we add a batch dimension (axis=0)
prediction = model.predict(np.expand_dims(sample_image, axis=0))

# The prediction is an array of 10 probabilities; the index of the highest probability is the predicted digit
predicted_label = np.argmax(prediction[0])

# Visualize the sample image and the result
plt.figure()
# Reshape the image back to 28x28 for plotting
plt.imshow(sample_image.reshape(28, 28), cmap='gray')
plt.title(f"True Label: {true_label}, Predicted: {predicted_label}")
plt.axis('off')
plt.show()

import cv2 # OpenCV is great for image processing
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files # Tool for uploading files in Colab

# --- A. Upload and Load the New Image ---
def load_and_prepare_new_image():
    # 1. Prompt user to upload a file
    uploaded = files.upload()

    # Get the file name (assuming only one file is uploaded)
    filename = next(iter(uploaded))

    print(f"\nUploaded file: {filename}")

    # 2. Load the image in grayscale (flag 0)
    # Ensure your image is a hand-drawn digit on a white background or similar
    img = cv2.imread(filename, 0)

    if img is None:
        print("Error: Could not load image.")
        return None

    # 3. Resize the image to 28x28 pixels
    # This is necessary because the CNN input layer expects 28x28
    img_resized = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)

    # 4. Invert and Normalize the Image
    # MNIST data is white digit on black background, but a photo is usually the opposite.
    # We must match the data format the model was trained on.

    # Invert colors (255 - pixel value)
    img_inverted = cv2.bitwise_not(img_resized)

    # Convert to float32 and normalize (0-255 to 0-1)
    img_normalized = img_inverted.astype('float32') / 255.0

    # 5. Reshape for the Model
    # The model expects a batch dimension (1) and a channel dimension (1)
    # Shape goes from (28, 28) -> (1, 28, 28, 1)
    img_input = img_normalized.reshape(1, 28, 28, 1)

    print(f"Prepared image shape for model: {img_input.shape}")

    return img_input, img_normalized # Return both for prediction and visualization

# --- B. Make Prediction and Visualize ---
try:
    new_image_input, new_image_visual = load_and_prepare_new_image()

    if new_image_input is not None:
        print("\nMaking prediction...")

        # 1. Get the model's prediction (array of 10 probabilities)
        prediction = model.predict(new_image_input)

        # 2. Find the digit with the highest probability
        predicted_label = np.argmax(prediction[0])

        # 3. Find the confidence (the highest probability)
        confidence = np.max(prediction[0]) * 100

        # 4. Display the result
        plt.figure(figsize=(4, 4))
        plt.imshow(new_image_visual, cmap='gray')
        plt.title(f"Predicted Digit: {predicted_label}\nConfidence: {confidence:.2f}%",
                  fontsize=14, color='green' if confidence > 80 else 'red')
        plt.axis('off')
        plt.show()

        # 5. Optional: Show the full probability breakdown
        print("\nFull Probability Breakdown:")
        for i, prob in enumerate(prediction[0]):
            print(f"  Digit {i}: {prob*100:.2f}%")

except Exception as e:
    print(f"An error occurred: {e}")

import cv2 # OpenCV is great for image processing
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files # Tool for uploading files in Colab

# --- A. Upload and Load the New Image ---
def load_and_prepare_new_image():
    # 1. Prompt user to upload a file
    uploaded = files.upload()

    # Get the file name (assuming only one file is uploaded)
    filename = next(iter(uploaded))

    print(f"\nUploaded file: {filename}")

    # 2. Load the image in grayscale (flag 0)
    # Ensure your image is a hand-drawn digit on a white background or similar
    img = cv2.imread(filename, 0)

    if img is None:
        print("Error: Could not load image.")
        return None

    # 3. Resize the image to 28x28 pixels
    # This is necessary because the CNN input layer expects 28x28
    img_resized = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)

    # 4. Invert and Normalize the Image
    # MNIST data is white digit on black background, but a photo is usually the opposite.
    # We must match the data format the model was trained on.

    # Invert colors (255 - pixel value)
    img_inverted = cv2.bitwise_not(img_resized)

    # Convert to float32 and normalize (0-255 to 0-1)
    img_normalized = img_inverted.astype('float32') / 255.0

    # 5. Reshape for the Model
    # The model expects a batch dimension (1) and a channel dimension (1)
    # Shape goes from (28, 28) -> (1, 28, 28, 1)
    img_input = img_normalized.reshape(1, 28, 28, 1)

    print(f"Prepared image shape for model: {img_input.shape}")

    return img_input, img_normalized # Return both for prediction and visualization

# --- B. Make Prediction and Visualize ---
try:
    new_image_input, new_image_visual = load_and_prepare_new_image()

    if new_image_input is not None:
        print("\nMaking prediction...")

        # 1. Get the model's prediction (array of 10 probabilities)
        prediction = model.predict(new_image_input)

        # 2. Find the digit with the highest probability
        predicted_label = np.argmax(prediction[0])

        # 3. Find the confidence (the highest probability)
        confidence = np.max(prediction[0]) * 100

        # 4. Display the result
        plt.figure(figsize=(4, 4))
        plt.imshow(new_image_visual, cmap='gray')
        plt.title(f"Predicted Digit: {predicted_label}\nConfidence: {confidence:.2f}%",
                  fontsize=14, color='green' if confidence > 80 else 'red')
        plt.axis('off')
        plt.show()

        # 5. Optional: Show the full probability breakdown
        print("\nFull Probability Breakdown:")
        for i, prob in enumerate(prediction[0]):
            print(f"  Digit {i}: {prob*100:.2f}%")

except Exception as e:
    print(f"An error occurred: {e}")

import cv2 # OpenCV is great for image processing
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files # Tool for uploading files in Colab

# --- A. Upload and Load the New Image ---
def load_and_prepare_new_image():
    # 1. Prompt user to upload a file
    uploaded = files.upload()

    # Get the file name (assuming only one file is uploaded)
    filename = next(iter(uploaded))

    print(f"\nUploaded file: {filename}")

    # 2. Load the image in grayscale (flag 0)
    # Ensure your image is a hand-drawn digit on a white background or similar
    img = cv2.imread(filename, 0)

    if img is None:
        print("Error: Could not load image.")
        return None

    # 3. Resize the image to 28x28 pixels
    # This is necessary because the CNN input layer expects 28x28
    img_resized = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)

    # 4. Invert and Normalize the Image
    # MNIST data is white digit on black background, but a photo is usually the opposite.
    # We must match the data format the model was trained on.

    # Invert colors (255 - pixel value)
    img_inverted = cv2.bitwise_not(img_resized)

    # Convert to float32 and normalize (0-255 to 0-1)
    img_normalized = img_inverted.astype('float32') / 255.0

    # 5. Reshape for the Model
    # The model expects a batch dimension (1) and a channel dimension (1)
    # Shape goes from (28, 28) -> (1, 28, 28, 1)
    img_input = img_normalized.reshape(1, 28, 28, 1)

    print(f"Prepared image shape for model: {img_input.shape}")

    return img_input, img_normalized # Return both for prediction and visualization

# --- B. Make Prediction and Visualize ---
try:
    new_image_input, new_image_visual = load_and_prepare_new_image()

    if new_image_input is not None:
        print("\nMaking prediction...")

        # 1. Get the model's prediction (array of 10 probabilities)
        prediction = model.predict(new_image_input)

        # 2. Find the digit with the highest probability
        predicted_label = np.argmax(prediction[0])

        # 3. Find the confidence (the highest probability)
        confidence = np.max(prediction[0]) * 100

        # 4. Display the result
        plt.figure(figsize=(4, 4))
        plt.imshow(new_image_visual, cmap='gray')
        plt.title(f"Predicted Digit: {predicted_label}\nConfidence: {confidence:.2f}%",
                  fontsize=14, color='green' if confidence > 80 else 'red')
        plt.axis('off')
        plt.show()

        # 5. Optional: Show the full probability breakdown
        print("\nFull Probability Breakdown:")
        for i, prob in enumerate(prediction[0]):
            print(f"  Digit {i}: {prob*100:.2f}%")

except Exception as e:
    print(f"An error occurred: {e}")